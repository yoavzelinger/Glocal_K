{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ty3gYQgtnwFA"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nl2tU6kL8Ot3"
      },
      "outputs": [],
      "source": [
        "# %tensorflow_version 1.x\n",
        "from time import time\n",
        "from scipy.sparse import csc_matrix\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "import pickle\n",
        "\n",
        "FIX_LEAKAGE = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pcyWCv_WvSKC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4A9uU1WloQ2"
      },
      "source": [
        "# Data Loader Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Yoav and Yehonatan Addition - Fixing the Data Leakage\n",
        "Split the data into train and test based on the timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_time_split_100k(\n",
        "        ratings,\n",
        "        test_size=0.2,\n",
        "        fix_leakage=True\n",
        " ):\n",
        "    \"\"\"\n",
        "    split the data into training and testing set\n",
        "\n",
        "    parameters:\n",
        "        ratings: the ratings matrix\n",
        "        test_size: the size of the testing set\n",
        "\n",
        "    returns:\n",
        "        the training and testing set\n",
        "    \"\"\"\n",
        "    if fix_leakage:\n",
        "        ratings = ratings[ratings[:,3].argsort()]\n",
        "    test_size = int(len(ratings) * test_size)\n",
        "    train = ratings[:-test_size]\n",
        "    test = ratings[-test_size:]\n",
        "    if fix_leakage:\n",
        "        train_users, train_items = set(train[:, 0]), set(train[:, 1])\n",
        "        test = test[[(test_record[0] in train_users and test_record[1] in train_items) for test_record in test]]\n",
        "        user_id_dict, item_id_dict = {}, {}\n",
        "        for i, user_id in enumerate(np.unique(train[:,0]).tolist()):\n",
        "            user_id_dict[user_id] = i\n",
        "        for i, item_id in enumerate(np.unique(train[:,1]).tolist()):\n",
        "            item_id_dict[item_id] = i\n",
        "        train = np.array([(user_id_dict[record[0]], item_id_dict[record[1]], record[2], record[3]) for record in train])\n",
        "        test = np.array([(user_id_dict[record[0]], item_id_dict[record[1]], record[2], record[3]) for record in test])\n",
        "    return train, test\n",
        "\n",
        "def train_test_time_split_1m(\n",
        "        ratings,\n",
        "        seed=1234,\n",
        "        fix_leakage=True\n",
        " ):\n",
        "    \"\"\"\n",
        "    split the data into training and testing set\n",
        "\n",
        "    parameters:\n",
        "        ratings: the ratings matrix\n",
        "        test_size: the size of the testing set\n",
        "\n",
        "    returns:\n",
        "        the sorted ratings\n",
        "    \"\"\"\n",
        "    if fix_leakage:\n",
        "        ratings = ratings[(-ratings[:,3]).argsort()]\n",
        "    else:\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(ratings)\n",
        "    return ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Continue of original code\n",
        "Adding a call to the function. If the above cell isn't run then it take action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cq3KEUaVo1o3"
      },
      "outputs": [],
      "source": [
        "def load_data_100k(path='./', delimiter='\\t'):\n",
        "\n",
        "    train = np.loadtxt(path+'movielens_100k_u1.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    test = np.loadtxt(path+'movielens_100k_u1.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    total = np.concatenate((train, test), axis=0)\n",
        "    train, test = train_test_time_split_100k(total, test_size=(len(test) / len(total)), fix_leakage=FIX_LEAKAGE)\n",
        "    n_u = np.unique(train[:,0]).size  # num of users\n",
        "    n_m = np.unique(train[:,1]).size  # num of movies\n",
        "    n_train = train.shape[0]  # num of training ratings\n",
        "    n_test = test.shape[0]  # num of test ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_train):\n",
        "        train_r[train[i,1]-1, train[i,0]-1] = train[i,2]\n",
        "\n",
        "    for i in range(n_test):\n",
        "        test_r[test[i,1]-1, test[i,0]-1] = test[i,2]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P3e8Xg3us8g7"
      },
      "outputs": [],
      "source": [
        "def load_data_1m(path='./', delimiter='::', frac=0.1, seed=1234):\n",
        "\n",
        "    tic = time()\n",
        "    print('reading data...')\n",
        "    data = np.loadtxt(path+'movielens_1m_dataset.dat', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    data = train_test_time_split_1m(data, seed=seed, fix_leakage=FIX_LEAKAGE)\n",
        "    print('taken', time() - tic, 'seconds')\n",
        "\n",
        "    n_u = np.unique(data[:,0]).size  # num of users\n",
        "    n_m = np.unique(data[:,1]).size  # num of movies\n",
        "    n_r = data.shape[0]  # num of ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    udict, mdict = {}, {}\n",
        "    \n",
        "    max_train_time, min_test_time = -1, np.inf\n",
        "    for i in range(n_r - 1, -1, -1):\n",
        "        u_id, m_id, r, timestamp = data[i]\n",
        "\n",
        "        if i < int(frac * n_r): # test set\n",
        "            if u_id in udict and m_id in mdict:\n",
        "                min_test_time = min(min_test_time, timestamp)\n",
        "                test_r[mdict[m_id], udict[u_id]] = r\n",
        "        else: # training set\n",
        "            if u_id not in udict:\n",
        "                udict[u_id] = len(udict)\n",
        "            if m_id not in mdict:\n",
        "                mdict[m_id] = len(mdict)\n",
        "            max_train_time = max(max_train_time, timestamp)\n",
        "            train_r[mdict[m_id], udict[u_id]] = r\n",
        "\n",
        "    assert max_train_time < min_test_time, f\"{max_train_time} < {min_test_time}\"\n",
        "\n",
        "    n_u, n_m = len(udict), len(mdict)\n",
        "    train_r, test_r = train_r[:n_m, :n_u], test_r[:n_m, :n_u]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    n_train = np.sum(train_m, dtype='int32')\n",
        "    n_test = np.sum(test_m, dtype='int32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7rMjcbLvhtRs"
      },
      "outputs": [],
      "source": [
        "def load_matlab_file(path_file, name_field):\n",
        "    \n",
        "    db = h5py.File(path_file, 'r')\n",
        "    ds = db[name_field]\n",
        "\n",
        "    try:\n",
        "        if 'ir' in ds.keys():\n",
        "            data = np.asarray(ds['data'])\n",
        "            ir   = np.asarray(ds['ir'])\n",
        "            jc   = np.asarray(ds['jc'])\n",
        "            out  = csc_matrix((data, ir, jc)).astype(np.float32)\n",
        "    except AttributeError:\n",
        "        out = np.asarray(ds).astype(np.float32).T\n",
        "\n",
        "    db.close()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g6pIUrkza2zv"
      },
      "outputs": [],
      "source": [
        "def load_data_monti(path='./'):\n",
        "\n",
        "    M = load_matlab_file(path+'douban_monti_dataset.mat', 'M')\n",
        "    Otraining = load_matlab_file(path+'douban_monti_dataset.mat', 'Otraining') * M\n",
        "    Otest = load_matlab_file(path+'douban_monti_dataset.mat', 'Otest') * M\n",
        "\n",
        "    n_u = M.shape[0]  # num of users\n",
        "    n_m = M.shape[1]  # num of movies\n",
        "    n_train = Otraining[np.where(Otraining)].size  # num of training ratings\n",
        "    n_test = Otest[np.where(Otest)].size  # num of test ratings\n",
        "\n",
        "    train_r = Otraining.T\n",
        "    test_r = Otest.T\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8kEkg9mlIW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0fkA1WpmipzF"
      },
      "outputs": [],
      "source": [
        "# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "data_path = 'data'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ijlu0lXQioYM"
      },
      "outputs": [],
      "source": [
        "# Select a dataset among 'ML-1M', 'ML-100K', and 'Douban'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "dataset = 'ML-1M'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "# Yoav and Yehonatan\n",
        "# Select dims of the MF model among 25, 50, 75, 100\n",
        "dims = 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sJqSSY33mgkw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading data...\n",
            "taken 5.092442989349365 seconds\n",
            "data matrix loaded\n",
            "num of users: 6011\n",
            "num of movies: 3678\n",
            "num of training ratings: 900189\n",
            "num of test ratings: 95722\n",
            "matrix factorization prediction loaded\n"
          ]
        }
      ],
      "source": [
        "# Data Load\n",
        "try:\n",
        "    if dataset == 'ML-100K':\n",
        "        path = data_path + '/MovieLens_100K/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(path=path, delimiter='\\t')\n",
        "\n",
        "    elif dataset == 'ML-1M':\n",
        "        path = data_path + '/MovieLens_1M/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_1m(path=path, delimiter='::', frac=0.1, seed=1234)\n",
        "\n",
        "    elif dataset == 'Douban':\n",
        "        path = data_path + '/Douban_monti/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_monti(path=path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "    \n",
        "    with open(path + f\"mf_prediction_{dims}_dims.pickle\", \"rb\") as f:\n",
        "        mf_prediction = pickle.load(f)\n",
        "\n",
        "    mf_prediction = tf.convert_to_tensor(mf_prediction.T, dtype=tf.float32)\n",
        "    print(\"matrix factorization prediction loaded\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "    print('Error: Unable to load data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'train_test_union: 6011, train: 6011, test: 1179, train_test_inter: 1179, test_minus_train: 0'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify no cold start users in test set\n",
        "train_users_set = set(np.where(np.sum(train_m, axis=0) > 0)[0])\n",
        "test_users_set = set(np.where(np.sum(test_m, axis=0) > 0)[0])\n",
        "str(f\"train_test_union: {len(train_users_set.union(test_users_set))}, train: {len(train_users_set)}, test: {len(test_users_set)}, train_test_inter: {len(train_users_set.intersection(test_users_set))}, test_minus_train: {len(test_users_set - train_users_set)}\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMtA9yml-gp"
      },
      "source": [
        "# Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nGCdp_FlobOK"
      },
      "outputs": [],
      "source": [
        "# Common hyperparameter settings\n",
        "n_hid = 500\n",
        "n_dim = 5\n",
        "n_layers = 2\n",
        "gk_size = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "344bwGB0cWXp"
      },
      "outputs": [],
      "source": [
        "# Different hyperparameter settings for each dataset\n",
        "if dataset == 'ML-100K':\n",
        "    lambda_2 = 20.  # l2 regularisation\n",
        "    lambda_s = 0.006\n",
        "    iter_p = 5  # optimisation\n",
        "    iter_f = 5\n",
        "    epoch_p = 30  # training epoch\n",
        "    epoch_f = 60\n",
        "    dot_scale = 1  # scaled dot product\n",
        "\n",
        "elif dataset == 'ML-1M':\n",
        "    lambda_2 = 70.\n",
        "    lambda_s = 0.018\n",
        "    iter_p = 50\n",
        "    iter_f = 10\n",
        "    epoch_p = 20\n",
        "    epoch_f = 30\n",
        "    dot_scale = 0.5\n",
        "\n",
        "elif dataset == 'Douban':\n",
        "    lambda_2 = 10.\n",
        "    lambda_s = 0.022\n",
        "    iter_p = 5\n",
        "    iter_f = 5\n",
        "    epoch_p = 20\n",
        "    epoch_f = 60\n",
        "    dot_scale = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b94aimX3nAMI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\2682195965.py:1: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "R = tf.placeholder(\"float\", [n_m, n_u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWtU4-pmDDT"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wX2wREO09zde"
      },
      "outputs": [],
      "source": [
        "def local_kernel(u, v):\n",
        "\n",
        "    dist = tf.norm(u - v, ord=2, axis=2)\n",
        "    hat = tf.maximum(0., 1. - dist**2)\n",
        "\n",
        "    return hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c88l9LYr9175"
      },
      "outputs": [],
      "source": [
        "def kernel_layer(x, n_hid=n_hid, n_dim=n_dim, activation=tf.nn.sigmoid, lambda_s=lambda_s, lambda_2=lambda_2, name=''):\n",
        "\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        W = tf.get_variable('W', [x.shape[1], n_hid])   # w(d) (users(n)*h)\n",
        "        n_in = x.get_shape().as_list()[1]\n",
        "        u = tf.get_variable('u', initializer=tf.random.truncated_normal([n_in, 1, n_dim], 0., 1e-3))\n",
        "        v = tf.get_variable('v', initializer=tf.random.truncated_normal([1, n_hid, n_dim], 0., 1e-3))\n",
        "        b = tf.get_variable('b', [n_hid])\n",
        "\n",
        "    w_hat = local_kernel(u, v)\n",
        "    \n",
        "    sparse_reg = tf.contrib.layers.l2_regularizer(lambda_s)\n",
        "    sparse_reg_term = tf.contrib.layers.apply_regularization(sparse_reg, [w_hat])\n",
        "    \n",
        "    l2_reg = tf.contrib.layers.l2_regularizer(lambda_2)\n",
        "    l2_reg_term = tf.contrib.layers.apply_regularization(l2_reg, [W])\n",
        "\n",
        "    W_eff = W * w_hat  # Local kernelised weight matrix\n",
        "    y = tf.matmul(x, W_eff) + b\n",
        "    y = activation(y)\n",
        "\n",
        "    return y, sparse_reg_term + l2_reg_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rlb95FmRVATa"
      },
      "outputs": [],
      "source": [
        "def global_kernel(input, gk_size, dot_scale):\n",
        "\n",
        "    avg_pooling = tf.reduce_mean(input, axis=1)  # Item (axis=1) based average pooling\n",
        "    avg_pooling = tf.reshape(avg_pooling, [1, -1])\n",
        "    n_kernel = avg_pooling.shape[1].value\n",
        "    \n",
        "    conv_kernel = tf.get_variable('conv_kernel', initializer=tf.random.truncated_normal([n_kernel, gk_size**2], stddev=0.1))\n",
        "    gk = tf.matmul(avg_pooling, conv_kernel) * dot_scale  # Scaled dot product\n",
        "    gk = tf.reshape(gk, [gk_size, gk_size, 1, 1])\n",
        "\n",
        "    return gk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jTLi_65XzIbH"
      },
      "outputs": [],
      "source": [
        "def global_conv(input, W):\n",
        "\n",
        "    input = tf.reshape(input, [1, input.shape[0], input.shape[1], 1])\n",
        "    conv2d = tf.nn.relu(tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME'))\n",
        "\n",
        "    return tf.reshape(conv2d, [conv2d.shape[1], conv2d.shape[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sQCwrSmKG4"
      },
      "source": [
        "# Network Instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtWj1SCo1RW"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7teUrgWagpW0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\770935157.py:3: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\770935157.py:3: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\770935157.py:4: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\t-yzelinger\\AppData\\Local\\anaconda3\\envs\\recsys_venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, reg_loss = kernel_layer(y, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_p, reg_loss = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_p)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_p = sqE + reg_losses\n",
        "\n",
        "optimizer_p = tf.contrib.opt.ScipyOptimizerInterface(loss_p, options={'disp': True, 'maxiter': iter_p, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IEBsNhNo4Cj"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OiTXqnN6zLXQ"
      },
      "outputs": [],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, _ = kernel_layer(y, name=str(i))\n",
        "\n",
        "y_dash, _ = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "\n",
        "# y_dash = (y_dash + mf_prediction) / 2\n",
        "\n",
        "gk = global_kernel(y_dash, gk_size, dot_scale)  # Global kernel\n",
        "y_hat = global_conv(train_r, gk)  # Global kernel-based rating matrix\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y_hat, reg_loss = kernel_layer(y_hat, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_f, reg_loss = kernel_layer(y_hat, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_f)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_f = sqE + reg_losses\n",
        "\n",
        "optimizer_f = tf.contrib.opt.ScipyOptimizerInterface(loss_f, options={'disp': True, 'maxiter': iter_f, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETwz58aK6y6"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vyReXxgac3KH"
      },
      "outputs": [],
      "source": [
        "def dcg_k(score_label, k):\n",
        "    dcg, i = 0., 0\n",
        "    for s in score_label:\n",
        "        if i < k:\n",
        "            dcg += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    return dcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jwsSR-8ZdGWo"
      },
      "outputs": [],
      "source": [
        "def ndcg_k(y_hat, y, k):\n",
        "    score_label = np.stack([y_hat, y], axis=1).tolist()\n",
        "    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n",
        "    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n",
        "    norm, i = 0., 0\n",
        "    for s in score_label_:\n",
        "        if i < k:\n",
        "            norm += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    dcg = dcg_k(score_label, k)\n",
        "    return dcg / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yy9eQS51pbhj"
      },
      "outputs": [],
      "source": [
        "def call_ndcg(y_hat, y):\n",
        "    ndcg_sum, num = 0, 0\n",
        "    y_hat, y = y_hat.T, y.T\n",
        "    n_users = y.shape[0]\n",
        "\n",
        "    for i in range(n_users):\n",
        "        y_hat_i = y_hat[i][np.where(y[i])]\n",
        "        y_i = y[i][np.where(y[i])]\n",
        "\n",
        "        if y_i.shape[0] < 2:\n",
        "            continue\n",
        "\n",
        "        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n",
        "        num += 1\n",
        "\n",
        "    return ndcg_sum / num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXQjeMxmYEC"
      },
      "source": [
        "# Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UZ35Zoha-Eue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\922873020.py:5: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\t-yzelinger\\AppData\\Local\\Temp\\ipykernel_33996\\922873020.py:7: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 461407.093750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 1 test rmse: 0.95945346 train rmse: 0.87171835\n",
            "Time: 59.93947243690491 seconds\n",
            "Time cumulative: 59.93947243690491 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 460442.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 11\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 1 test rmse: 0.958909 test mae: 0.7394769 test ndcg: 0.9008505591996923\n",
            "Epoch: 1 train rmse: 0.8707909 train mae: 0.6835623 train ndcg: 0.9153803572965367\n",
            "Time: 68.90406894683838 seconds\n",
            "Time cumulative: 128.8435413837433 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 456335.406250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 2 test rmse: 0.9460937 test mae: 0.73214823 test ndcg: 0.9016981110356633\n",
            "Epoch: 2 train rmse: 0.86625016 train mae: 0.6819116 train ndcg: 0.9162349975934684\n",
            "Time: 64.78856778144836 seconds\n",
            "Time cumulative: 193.63210916519165 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 453348.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 3 test rmse: 0.9403815 test mae: 0.727652 test ndcg: 0.9026548718584454\n",
            "Epoch: 3 train rmse: 0.86286867 train mae: 0.67850435 train ndcg: 0.9165809830268496\n",
            "Time: 67.93265914916992 seconds\n",
            "Time cumulative: 261.5647683143616 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 451854.000000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 4 test rmse: 0.9338976 test mae: 0.7246692 test ndcg: 0.9034023701755138\n",
            "Epoch: 4 train rmse: 0.8616667 train mae: 0.6785987 train ndcg: 0.9172257526646402\n",
            "Time: 63.01122426986694 seconds\n",
            "Time cumulative: 324.5759925842285 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 449545.937500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 5 test rmse: 0.9299117 test mae: 0.72103435 test ndcg: 0.9040406291850935\n",
            "Epoch: 5 train rmse: 0.8592538 train mae: 0.6753945 train ndcg: 0.9176282842758698\n",
            "Time: 51.0701425075531 seconds\n",
            "Time cumulative: 375.6461350917816 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 447704.375000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 6 test rmse: 0.9250246 test mae: 0.71887493 test ndcg: 0.903931495569142\n",
            "Epoch: 6 train rmse: 0.85765177 train mae: 0.6750371 train ndcg: 0.9180536513739272\n",
            "Time: 53.60726976394653 seconds\n",
            "Time cumulative: 429.25340485572815 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 446014.062500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 7 test rmse: 0.9205779 test mae: 0.7161733 test ndcg: 0.9040971812294712\n",
            "Epoch: 7 train rmse: 0.85586697 train mae: 0.67382973 train ndcg: 0.918283617991647\n",
            "Time: 55.36517524719238 seconds\n",
            "Time cumulative: 484.61858010292053 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 444503.031250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 8 test rmse: 0.9172095 test mae: 0.71489084 test ndcg: 0.9044362252194894\n",
            "Epoch: 8 train rmse: 0.854776 train mae: 0.67349446 train ndcg: 0.9188919344017461\n",
            "Time: 62.444050788879395 seconds\n",
            "Time cumulative: 547.0626308917999 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 442794.187500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 9 test rmse: 0.91605675 test mae: 0.7135151 test ndcg: 0.9047443738709412\n",
            "Epoch: 9 train rmse: 0.8530321 train mae: 0.6704398 train ndcg: 0.9191580999480115\n",
            "Time: 52.50964069366455 seconds\n",
            "Time cumulative: 599.5722715854645 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 441586.562500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 10 test rmse: 0.9138656 test mae: 0.7125065 test ndcg: 0.9049308964386629\n",
            "Epoch: 10 train rmse: 0.85180306 train mae: 0.67023927 train ndcg: 0.9195039399185304\n",
            "Time: 57.86624050140381 seconds\n",
            "Time cumulative: 657.4385120868683 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 440332.375000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 11 test rmse: 0.91174483 test mae: 0.7116454 test ndcg: 0.905178029659711\n",
            "Epoch: 11 train rmse: 0.8508129 train mae: 0.6695676 train ndcg: 0.9198357188188575\n",
            "Time: 61.808844566345215 seconds\n",
            "Time cumulative: 719.2473566532135 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 438946.687500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 12 test rmse: 0.91127825 test mae: 0.7114033 test ndcg: 0.9051561329748591\n",
            "Epoch: 12 train rmse: 0.8495486 train mae: 0.66851383 train ndcg: 0.9200640437625598\n",
            "Time: 54.97745442390442 seconds\n",
            "Time cumulative: 774.2248110771179 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 437738.656250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 13 test rmse: 0.9098652 test mae: 0.7103762 test ndcg: 0.9053190603179542\n",
            "Epoch: 13 train rmse: 0.8482817 train mae: 0.66726536 train ndcg: 0.9203955945912815\n",
            "Time: 58.61740159988403 seconds\n",
            "Time cumulative: 832.842212677002 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 436897.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 14 test rmse: 0.90893424 test mae: 0.7098247 test ndcg: 0.9054957238747487\n",
            "Epoch: 14 train rmse: 0.84768057 train mae: 0.6668267 train ndcg: 0.9209041557947988\n",
            "Time: 57.57366919517517 seconds\n",
            "Time cumulative: 890.4158818721771 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 435861.937500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 15 test rmse: 0.907514 test mae: 0.7089763 test ndcg: 0.9055012572435333\n",
            "Epoch: 15 train rmse: 0.84664845 train mae: 0.6660419 train ndcg: 0.9208740784882935\n",
            "Time: 61.598905086517334 seconds\n",
            "Time cumulative: 952.0147869586945 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 434773.562500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 16 test rmse: 0.90727824 test mae: 0.7088786 test ndcg: 0.9053845042234903\n",
            "Epoch: 16 train rmse: 0.8456625 train mae: 0.6653016 train ndcg: 0.9212830366228831\n",
            "Time: 52.184542417526245 seconds\n",
            "Time cumulative: 1004.1993293762207 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 433629.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 17 test rmse: 0.9064179 test mae: 0.7082214 test ndcg: 0.9053935978583412\n",
            "Epoch: 17 train rmse: 0.8446579 train mae: 0.66421217 train ndcg: 0.9216319167034543\n",
            "Time: 53.87232828140259 seconds\n",
            "Time cumulative: 1058.0716576576233 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 432145.906250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 18 test rmse: 0.906373 test mae: 0.70807797 test ndcg: 0.9054240907004528\n",
            "Epoch: 18 train rmse: 0.8433742 train mae: 0.6629253 train ndcg: 0.9219333281270322\n",
            "Time: 53.37546992301941 seconds\n",
            "Time cumulative: 1111.4471275806427 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 430388.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 19 test rmse: 0.9046205 test mae: 0.707597 test ndcg: 0.906122300067764\n",
            "Epoch: 19 train rmse: 0.84211844 train mae: 0.6627866 train ndcg: 0.922579430606943\n",
            "Time: 63.99743103981018 seconds\n",
            "Time cumulative: 1175.4445586204529 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 429104.625000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 20 test rmse: 0.90543914 test mae: 0.70764667 test ndcg: 0.90619703892264\n",
            "Epoch: 20 train rmse: 0.8409424 train mae: 0.6609189 train ndcg: 0.9229243660921288\n",
            "Time: 62.281720876693726 seconds\n",
            "Time cumulative: 1237.7262794971466 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 428024.437500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 21 test rmse: 0.90399474 test mae: 0.7069263 test ndcg: 0.9056119768362039\n",
            "Epoch: 21 train rmse: 0.83991265 train mae: 0.6604324 train ndcg: 0.922980988758262\n",
            "Time: 48.807300329208374 seconds\n",
            "Time cumulative: 1286.533579826355 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 427210.812500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 14\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 22 test rmse: 0.903834 test mae: 0.70674396 test ndcg: 0.9063009144460841\n",
            "Epoch: 22 train rmse: 0.8391431 train mae: 0.65992427 train ndcg: 0.9232739906220084\n",
            "Time: 61.407233476638794 seconds\n",
            "Time cumulative: 1347.9408133029938 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 426090.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 23 test rmse: 0.90359974 test mae: 0.7066679 test ndcg: 0.9064227527510779\n",
            "Epoch: 23 train rmse: 0.83850104 train mae: 0.6594238 train ndcg: 0.9239258013668259\n",
            "Time: 58.558189153671265 seconds\n",
            "Time cumulative: 1406.499002456665 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 425030.906250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 24 test rmse: 0.9031699 test mae: 0.70626855 test ndcg: 0.9064485076327065\n",
            "Epoch: 24 train rmse: 0.83728975 train mae: 0.65826905 train ndcg: 0.9238425843221749\n",
            "Time: 55.670626401901245 seconds\n",
            "Time cumulative: 1462.1696288585663 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 424288.843750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 25 test rmse: 0.90184563 test mae: 0.70597047 test ndcg: 0.9065801868699788\n",
            "Epoch: 25 train rmse: 0.83695656 train mae: 0.65905225 train ndcg: 0.9241762816886019\n",
            "Time: 64.92284560203552 seconds\n",
            "Time cumulative: 1527.0924744606018 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 423331.312500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 14\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 26 test rmse: 0.9025982 test mae: 0.7057146 test ndcg: 0.9066792373059973\n",
            "Epoch: 26 train rmse: 0.8359263 train mae: 0.6569831 train ndcg: 0.9243903623301184\n",
            "Time: 58.58909630775452 seconds\n",
            "Time cumulative: 1585.6815707683563 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 422448.531250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 27 test rmse: 0.90218437 test mae: 0.70597315 test ndcg: 0.9065859513250238\n",
            "Epoch: 27 train rmse: 0.83532405 train mae: 0.65725774 train ndcg: 0.9246983799982496\n",
            "Time: 54.01844263076782 seconds\n",
            "Time cumulative: 1639.7000133991241 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 421590.281250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 15\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 28 test rmse: 0.90197897 test mae: 0.7056098 test ndcg: 0.9066913377117884\n",
            "Epoch: 28 train rmse: 0.8344005 train mae: 0.6559735 train ndcg: 0.9249167518497505\n",
            "Time: 53.75968527793884 seconds\n",
            "Time cumulative: 1693.459698677063 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 420918.406250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 29 test rmse: 0.9016875 test mae: 0.7053691 test ndcg: 0.9067831278861314\n",
            "Epoch: 29 train rmse: 0.8337948 train mae: 0.65569466 train ndcg: 0.9250455935335337\n",
            "Time: 59.88029909133911 seconds\n",
            "Time cumulative: 1753.339997768402 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
            "  Objective function value: 420087.156250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 30 test rmse: 0.90123665 test mae: 0.7051919 test ndcg: 0.9067156732392767\n",
            "Epoch: 30 train rmse: 0.8330454 train mae: 0.6551096 train ndcg: 0.9252257641659215\n",
            "Time: 65.49972915649414 seconds\n",
            "Time cumulative: 1818.8397269248962 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"
          ]
        }
      ],
      "source": [
        "best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n",
        "best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n",
        "\n",
        "time_cumulative = 0\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epoch_p):\n",
        "        tic = time()\n",
        "        optimizer_p.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_p, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('PRE-TRAINING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "        break\n",
        "\n",
        "    for i in range(epoch_f):\n",
        "        tic = time()\n",
        "        optimizer_f.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_f, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n",
        "        train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n",
        "\n",
        "        test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n",
        "        train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n",
        "\n",
        "        if test_rmse < best_rmse:\n",
        "            best_rmse = test_rmse\n",
        "            best_rmse_ep = i+1\n",
        "\n",
        "        if test_mae < best_mae:\n",
        "            best_mae = test_mae\n",
        "            best_mae_ep = i+1\n",
        "\n",
        "        if best_ndcg < test_ndcg:\n",
        "            best_ndcg = test_ndcg\n",
        "            best_ndcg_ep = i+1\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('FINE-TUNING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "        print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CTi_PdXJqTjh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 30  best rmse: 0.90123665\n",
            "Epoch: 30  best mae: 0.7051919\n",
            "Epoch: 29  best ndcg: 0.9067831278861314\n"
          ]
        }
      ],
      "source": [
        "# Final result\n",
        "print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n",
        "print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n",
        "print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GLocal_K.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "recsys_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
